{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\", \"corpus\": [ \"I am a data scientist\" ], \"negations\": [ \"I am not a data scientist\" ] }, \"start\": \"0001-01-01T00:00:00Z\", \"end\": \"0300-01-01T00:00:00Z\" } Example 9 Imagine that we have a database of mappings from integer values to corresponding IDs. The database is a single. When it is too big to fit in memory we want to use a sampling method to estimate the number of mappings in the database. Your method is calledin terms of the number of returned pairs (i.e., triplets) - so the overall required memory is given by- we can think in terms of pseudocode: Example 10 Imagine now that a mapping from integer IDs to non-integer values is of interest. That is, we do not know the value represented by an ID, but want to count the number of (integer) IDs who are associated to a non-integer. This can be approximated the usual way - just ignore the non-integer values. Example 11 With reference to example (10), there is an ambiguity which can now occur. Consider an integer value followed by a non-integer ID. In function we need to decide whether the (first) integer value is associated to a non-integer ID - or not. To do so, we could decide by running the function for the number of times, and\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "job_title = \"Data Scientist\"\n",
    "job_description = \"We are seeking a skilled data scientist to join our team. You will be responsible for analyzing and interpreting complex data sets to discover actionable insights.\"\n",
    "\n",
    "prompt = f\"Given the job title '{job_title}', and the following job description:\\n'{job_description}', please improve the job description:\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=\"davinci\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=300,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "improved_job_description = response.choices[0].text.strip()\n",
    "\n",
    "print(improved_job_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m890.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /home/harsh/miniconda3/envs/pyt/lib/python3.10/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /home/harsh/miniconda3/envs/pyt/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /home/harsh/miniconda3/envs/pyt/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/harsh/miniconda3/envs/pyt/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/harsh/miniconda3/envs/pyt/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/harsh/miniconda3/envs/pyt/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/harsh/miniconda3/envs/pyt/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.0 multidict-6.0.4 openai-0.27.8 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"Make this job description better: We are seeking a skilled data scientist to join our team. You will be responsible for analyzing and interpreting complex data sets to discover actionable insights.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7n2X7CmSzALJYOZJPSAiN9iOHgtv0 at 0x7fd39818c090> JSON: {\n",
       "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
       "  \"id\": \"cmpl-7n2X7CmSzALJYOZJPSAiN9iOHgtv0\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1691922165,\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nWe are looking for a passionate and experienced Data Scientist to join our dynamic\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"length\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 35,\n",
       "    \"completion_tokens\": 16,\n",
       "    \"total_tokens\": 51\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Make this job description better: We are seeking a skilled data scientist to join our team. You will be responsible for analyzing and interpreting complex data sets to discover actionable insights.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "job_description = \"We are looking for a software engineer with experience in Python and web development.\"\n",
    "\n",
    "# List of processed resumes\n",
    "resumes = [\n",
    "    \"Experienced software engineer with strong Python skills and a track record of web development.\",\n",
    "    \"Marketing professional with a passion for technology and coding.\",\n",
    "    \"Front-end developer specializing in JavaScript and responsive web design.\",\n",
    "    \"Recent graduate with a degree in computer science and internship experience in software development.\",]\n",
    "response_ = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": f\"Job Description: {job_description}\\nResume: {resumes[0]}\\nRate the suitability of this resume for the given job description on a scale of 1 to 10.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are actively looking for an exceptional and highly skilled data scientist to join our dynamic team. As a data scientist, you will play a pivotal role in analyzing and interpreting complex data sets with the aim of uncovering invaluable insights that drive actionable decisions.\\n\\nKey Responsibilities:\\n- Utilize advanced statistical methods and machine learning techniques to analyze large and intricate data sets.\\n- Develop innovative models to extract relevant information and identify patterns that guide business strategies and decision making.\\n- Collaborate closely with cross-functional teams to define data'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7n3lnXXou2P1kHXDV6waTffLspE8i at 0x7fd3672af600> JSON: {\n",
       "  \"id\": \"chatcmpl-7n3lnXXou2P1kHXDV6waTffLspE8i\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1691926919,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"I would rate the suitability of this resume for the given job description as an 8 out of 10. The resume clearly states that the candidate is an experienced software engineer and has strong Python skills, which aligns with the job description requirements. However, it would be helpful to have more specific details about the candidate's web development experience.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 63,\n",
       "    \"completion_tokens\": 68,\n",
       "    \"total_tokens\": 131\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     rankings\u001b[38;5;241m.\u001b[39mappend((resume, rating))\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Sort resumes based on the generated rankings\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mrankings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Print the ranked resumes\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRanked Resumes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [36], line 44\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     41\u001b[0m     rankings\u001b[38;5;241m.\u001b[39mappend((resume, rating))\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Sort resumes based on the generated rankings\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m rankings\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Print the ranked resumes\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRanked Resumes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "# openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# import openai\n",
    "\n",
    "# # Set your OpenAI API key here\n",
    "# openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# import openai\n",
    "\n",
    "# # Set your OpenAI API key here\n",
    "# openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "# Job description\n",
    "job_description = \"We are looking for a software engineer with experience in Python and web development.\"\n",
    "\n",
    "# List of processed resumes\n",
    "resumes = [\n",
    "    \"Experienced software engineer with strong Python skills and a track record of web development.\",\n",
    "    \"Marketing professional with a passion for technology and coding.\",\n",
    "    \"Front-end developer specializing in JavaScript and responsive web design.\",\n",
    "    \"Recent graduate with a degree in computer science and internship experience in software development.\",\n",
    "]\n",
    "\n",
    "# Rank resumes based on job description using GPT-3\n",
    "rankings = []\n",
    "\n",
    "for resume in resumes:\n",
    "    prompt = f\"Job Description: {job_description}\\nResume: {resume}\\nRate the suitability of this resume for the given job description on a scale of 1 to 10.\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci\",  # Use the davinci engine\n",
    "        prompt=prompt,\n",
    "        max_tokens=1,  # Set to 1 to get only the rating\n",
    "    )\n",
    "    \n",
    "    # Extract the rating from the GPT-3 response\n",
    "    rating = response.choices[0].text.strip()\n",
    "    rankings.append((resume, rating))\n",
    "\n",
    "# Sort resumes based on the generated rankings\n",
    "rankings.sort(key=lambda x: int(x[1]), reverse=True)\n",
    "\n",
    "# Print the ranked resumes\n",
    "print(\"Ranked Resumes:\")\n",
    "for idx, (resume, rating) in enumerate(rankings, start=1):\n",
    "    print(f\"{idx}. Resume: {resume}\\n   Rating: {rating}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('pyt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75ba99cab82ae3d1b68f6c82e3eb6569fe8478ff7a1b1bd0fcbd81a78982ddb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
